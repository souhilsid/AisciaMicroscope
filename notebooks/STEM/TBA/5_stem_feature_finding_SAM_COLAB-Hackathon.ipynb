{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to find features.\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pycroscopy/DTMicroscope/blob/main/notebooks/STEM/4_stem_feature_finding_SAM_COLAB-Hackathon.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyro5\n",
    "!pip install -q scifireaders\n",
    "!pip install -q sidpy\n",
    "!pip install -q pynsid\n",
    "!pip install -q git+https://github.com/pycroscopy/DTMicroscope.git@utk\n",
    "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "!pip install torch torchvision\n",
    "!pip install matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!run_server_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client side starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import Pyro5.api\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. connect to server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the microscope server\n",
    "uri = \"PYRO:microscope.server@localhost:9091\"\n",
    "mic_server = Pyro5.api.Proxy(uri)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download and Register dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "!gdown --id 16tqc8yqO5Vex6RHljBea3j_fV7Pkbhyq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. register dataset in the DigitalTwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize microscope and register data\n",
    "mic_server.initialize_microscope(\"STEM\")\n",
    "mic_server.register_data(\"test_stem.h5\")\n",
    "\n",
    "# Get overview image\n",
    "array_list, shape, dtype = mic_server.get_overview_image()\n",
    "im_array = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "\n",
    "# Display the overview image\n",
    "plt.imshow(im_array)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Overview Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM model to find features: You'll need a gpu instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Specify the model type and checkpoint URL\n",
    "model_type = \"vit_b\"  # Options: 'vit_b', 'vit_l', 'vit_h'\n",
    "checkpoint_url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
    "checkpoint_path = \"sam_vit_b_01ec64.pth\"\n",
    "\n",
    "# Download the checkpoint if not already present\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(\"Downloading SAM model checkpoint...\")\n",
    "    response = requests.get(checkpoint_url)\n",
    "    with open(checkpoint_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"SAM model checkpoint already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the SAM model\n",
    "sam = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
    "sam.to(device=device)\n",
    "# Initialize the automatic mask generator\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize im_array to the range [0, 1]\n",
    "im_array_normalized = (im_array - im_array.min()) / (im_array.max() - im_array.min())\n",
    "\n",
    "# Stack the normalized array to create an RGB image\n",
    "rgb_image = np.stack((im_array_normalized,) * 3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating masks...\")\n",
    "masks = mask_generator.generate(rgb_image)\n",
    "print(f\"Number of masks generated: {len(masks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "visual_image = rgb_image.copy()\n",
    "\n",
    "\n",
    "# Iterate through each mask and overlay it with a unique color\n",
    "for idx, mask in enumerate(masks, 1):  # Start counting from 1\n",
    "    segmentation = mask['segmentation']\n",
    "    # Generate a random color\n",
    "    color = np.random.randint(0, 255, (3,), dtype=np.uint8)\n",
    "    # Create a colored mask\n",
    "    colored_mask = np.zeros_like(visual_image)\n",
    "    colored_mask[segmentation] = color\n",
    "    # Blend the colored mask with the original image\n",
    "    visual_image = cv2.addWeighted(visual_image, 1.0, colored_mask, 0.5, 0)\n",
    "\n",
    "# Compute and store centroids\n",
    "centroids = []\n",
    "for idx, mask in enumerate(masks, 1):\n",
    "    segmentation = mask['segmentation']\n",
    "    # Find the coordinates of the mask pixels\n",
    "    coords = np.column_stack(np.where(segmentation))\n",
    "    if coords.size == 0:\n",
    "        continue  # Skip if mask is empty\n",
    "    # Compute the centroid\n",
    "    centroid = coords.mean(axis=0)\n",
    "    centroids.append((centroid[1], centroid[0], idx))  # (x, y, label)\n",
    "\n",
    "# Display the image with colored masks\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(visual_image)\n",
    "plt.axis('off')\n",
    "plt.title('Image with Segmentation Masks')\n",
    "plt.show()\n",
    "\n",
    "# Overlay the labels on the image\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(visual_image)\n",
    "ax = plt.gca()\n",
    "\n",
    "for (x, y, label) in centroids:\n",
    "    # Choose a contrasting color for the text\n",
    "    text_color = 'white' if np.mean(visual_image[int(y), int(x)]) < 128 else 'black'\n",
    "    ax.text(x, y, str(label), color=text_color, fontsize=12,\n",
    "            bbox=dict(facecolor='red' if text_color == 'white' else 'yellow', alpha=0.5, pad=1))\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('Image with Segmentation Masks and Labels')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
